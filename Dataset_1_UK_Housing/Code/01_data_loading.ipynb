{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c92d10",
   "metadata": {},
   "source": [
    "# UK Housing Price Prediction - Data Loading (2005-2017)\n",
    "\n",
    "**Author:** Abdul Salam Aldabik  \n",
    "**Date:** November 2025  \n",
    "**Course:** CloudAI - Machine Learning Project  \n",
    "**Dataset:** UK Housing Prices (2005-2017)\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "Load the full UK housing dataset with strategic filtering:\n",
    "- Time range: 2005-2017 (13 years)\n",
    "- Create temporal features\n",
    "- Generate summary statistics\n",
    "- Save processed dataset\n",
    "\n",
    "## CloudAI Reference\n",
    "- **Chapter 5:** Data Augmentation - Strategic sampling\n",
    "- **Chapter 6:** Time Series - Temporal feature extraction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f46f6b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a3266",
   "metadata": {},
   "source": [
    "## 2. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132662bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../Data')\n",
    "OUTPUT_DIR = DATA_DIR / 'loading_output'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_FILE = DATA_DIR / 'price_paid_records.csv'\n",
    "OUTPUT_FILE = DATA_DIR / 'housing_2005_2017.parquet'\n",
    "\n",
    "print(f\"✓ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a516f01",
   "metadata": {},
   "source": [
    "## 3. Load Data with Time Filtering\n",
    "\n",
    "**Strategy:** Load in chunks and filter by date range to manage memory efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6cb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range for filtering\n",
    "START_DATE = '2005-01-01'\n",
    "END_DATE = '2017-12-31'\n",
    "\n",
    "print(f\"Loading data from {START_DATE} to {END_DATE}...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "# Load in chunks for memory efficiency\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(DATA_FILE, chunksize=chunk_size, parse_dates=[2]), 1):\n",
    "    # Clean column names\n",
    "    chunk.columns = chunk.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('/', '_')\n",
    "    \n",
    "    # Filter by date range\n",
    "    chunk_filtered = chunk[(chunk['date_of_transfer'] >= START_DATE) & \n",
    "                           (chunk['date_of_transfer'] <= END_DATE)]\n",
    "    \n",
    "    if len(chunk_filtered) > 0:\n",
    "        chunks.append(chunk_filtered)\n",
    "    \n",
    "    # Progress update every 10 chunks\n",
    "    if i % 10 == 0:\n",
    "        print(f\"  Processed {i * chunk_size:,} rows...\")\n",
    "\n",
    "# Combine all chunks\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Data loaded: {len(df):,} transactions\")\n",
    "print(f\"✓ Date range: {df['date_of_transfer'].min()} to {df['date_of_transfer'].max()}\")\n",
    "print(f\"✓ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b847e",
   "metadata": {},
   "source": [
    "## 4. Create Temporal Features\n",
    "\n",
    "Extract time-based features for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temporal components\n",
    "df['year'] = df['date_of_transfer'].dt.year\n",
    "df['month'] = df['date_of_transfer'].dt.month\n",
    "df['quarter'] = df['date_of_transfer'].dt.quarter\n",
    "df['year_month'] = df['date_of_transfer'].dt.to_period('M')\n",
    "\n",
    "print(\"✓ Temporal features created\")\n",
    "print(f\"  Years covered: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"  Unique months: {df['year_month'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40dc74",
   "metadata": {},
   "source": [
    "## 5. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"Total transactions: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nPrice statistics:\")\n",
    "print(f\"  Mean: £{df['price'].mean():,.2f}\")\n",
    "print(f\"  Median: £{df['price'].median():,.0f}\")\n",
    "print(f\"  Range: £{df['price'].min():,.0f} - £{df['price'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92576b",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "\n",
    "### 6.1 Transaction Volume by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7020d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_counts = df.groupby('year').size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "bars = ax.bar(yearly_counts.index, yearly_counts.values, color='steelblue', \n",
    "              alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height/1000)}K',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Transactions', fontsize=12, fontweight='bold')\n",
    "ax.set_title('UK Housing Transactions by Year (2005-2017)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Highlight 2008 financial crisis\n",
    "ax.axvspan(2007.5, 2009.5, alpha=0.2, color='red', label='Financial Crisis')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / '01_yearly_volume.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: 01_yearly_volume.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3b5b1",
   "metadata": {},
   "source": [
    "### 6.2 Price Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_price = df.groupby('year')['price'].agg(['mean', 'median'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(yearly_price.index, yearly_price['mean'], \n",
    "        marker='o', linewidth=2.5, markersize=8, label='Mean Price', color='#2E86AB')\n",
    "ax.plot(yearly_price.index, yearly_price['median'], \n",
    "        marker='s', linewidth=2.5, markersize=8, label='Median Price', color='#A23B72')\n",
    "\n",
    "ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Price (£)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('UK House Price Trends (2005-2017)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'£{x/1000:.0f}K'))\n",
    "ax.legend(loc='upper left', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Mark financial crisis\n",
    "ax.axvspan(2007.5, 2009.5, alpha=0.15, color='red')\n",
    "ax.text(2008.5, yearly_price['mean'].max() * 0.95, 'Financial\\nCrisis', \n",
    "        ha='center', fontsize=10, fontweight='bold', color='darkred')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / '02_price_trends.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: 02_price_trends.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35cb1e",
   "metadata": {},
   "source": [
    "### 6.3 Seasonal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts = df.groupby('month').size()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "colors = sns.color_palette('coolwarm', 12)\n",
    "bars = ax.bar(range(1, 13), monthly_counts.values, color=colors, \n",
    "              alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "ax.set_xlabel('Month', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Total Transactions', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Seasonal Pattern: Housing Transactions by Month (2005-2017)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(range(1, 13))\n",
    "ax.set_xticklabels(month_names)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Highlight spring surge (Mar-May)\n",
    "ax.axvspan(2.5, 5.5, alpha=0.1, color='green', label='Spring Surge')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / '03_seasonal_pattern.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: 03_seasonal_pattern.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72664fd",
   "metadata": {},
   "source": [
    "### 6.4 Property Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_counts = df['property_type'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar chart with percentages\n",
    "bars = axes[0].bar(prop_counts.index, prop_counts.values, \n",
    "                   color='coral', alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "for i, (bar, count) in enumerate(zip(bars, prop_counts.values)):\n",
    "    pct = (count / len(df)) * 100\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., count,\n",
    "                f'{count/1000000:.1f}M\\n({pct:.1f}%)',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "axes[0].set_xlabel('Property Type', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Property Type Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "colors_pie = sns.color_palette('husl', len(prop_counts))\n",
    "axes[1].pie(prop_counts.values, labels=prop_counts.index, autopct='%1.1f%%',\n",
    "           startangle=90, colors=colors_pie, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Property Type Percentage', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / '04_property_types.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: 04_property_types.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176d157",
   "metadata": {},
   "source": [
    "### 6.5 Price Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Full range histogram\n",
    "axes[0].hist(df['price'], bins=100, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(df['price'].median(), color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Median: £{df[\"price\"].median():,.0f}')\n",
    "axes[0].set_xlabel('Price (£)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Price Distribution - Full Range', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Zoomed to 99th percentile\n",
    "price_99 = df['price'].quantile(0.99)\n",
    "price_filtered = df[df['price'] <= price_99]['price']\n",
    "axes[1].hist(price_filtered, bins=100, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(df['price'].median(), color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Price (£)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'Price Distribution - Bottom 99% (≤£{price_99:,.0f})', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / '05_price_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: 05_price_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0549381",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcdbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Parquet for efficiency\n",
    "df.to_parquet(OUTPUT_FILE, compression='gzip', index=False)\n",
    "\n",
    "file_size = OUTPUT_FILE.stat().st_size / 1024**2\n",
    "print(f\"✓ Data saved: {OUTPUT_FILE.name}\")\n",
    "print(f\"  File size: {file_size:.2f} MB\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d7504",
   "metadata": {},
   "source": [
    "## 8. Create Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file = OUTPUT_DIR / 'loading_summary.txt'\n",
    "\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"UK HOUSING DATA - LOADING SUMMARY (2005-2017)\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"DATA SELECTION:\\n\")\n",
    "    f.write(f\"  Time Range: 2005-2017\\n\")\n",
    "    f.write(f\"  Total Records: {len(df):,}\\n\\n\")\n",
    "    \n",
    "    f.write(\"PRICE STATISTICS:\\n\")\n",
    "    f.write(f\"  Mean: £{df['price'].mean():,.2f}\\n\")\n",
    "    f.write(f\"  Median: £{df['price'].median():,.0f}\\n\")\n",
    "    f.write(f\"  Min: £{df['price'].min():,.0f}\\n\")\n",
    "    f.write(f\"  Max: £{df['price'].max():,.0f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"TRANSACTIONS BY YEAR:\\n\")\n",
    "    f.write(yearly_counts.to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"PROPERTY TYPE DISTRIBUTION:\\n\")\n",
    "    f.write(prop_counts.to_string())\n",
    "\n",
    "print(f\"\\n✓ Summary report saved: {summary_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e703ad8",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### Data Loaded:\n",
    "- **Records:** 11.1M+ transactions\n",
    "- **Period:** 2005-2017 (13 years)\n",
    "- **Features:** Temporal features created\n",
    "\n",
    "### Key Insights:\n",
    "1. **2008 Financial Crisis:** Clear drop in transaction volume\n",
    "2. **Recovery:** Gradual increase from 2013 onwards\n",
    "3. **Seasonality:** Spring months show higher activity\n",
    "4. **Property Types:** Terraced houses most common\n",
    "\n",
    "### Next Steps:\n",
    "1. Add economic indicators (Bank of England data)\n",
    "2. Merge datasets\n",
    "3. Data cleaning and outlier handling\n",
    "4. Feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Complete**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
