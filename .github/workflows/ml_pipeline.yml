name: ML Model Training Pipeline

on:
  push:
    branches: [ main ]
    paths:
      - 'Dataset_1_UK_Housing/Code/**'
      - 'Dataset_2_UK_Historic_Electricity_Demand_Data/Code/**'
      - 'Dataset_1_UK_Housing/Data/**'
      - 'Dataset_2_UK_Historic_Electricity_Demand_Data/Data/**'
  workflow_dispatch:

jobs:
  retrain-housing-model:
    runs-on: ubuntu-latest
    name: Retrain Housing Price Model
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy scikit-learn joblib pycaret
        
    - name: Train Housing Model
      run: |
        cd Dataset_1_UK_Housing/Code
        python -c "
        import pandas as pd
        import numpy as np
        from sklearn.linear_model import Ridge
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler
        import joblib
        from pathlib import Path
        
        print('üè† Loading housing data...')
        data_path = Path('../Data/housing_features_final.parquet')
        if data_path.exists():
            df = pd.read_parquet(data_path)
            
            # Prepare features
            X = df.drop(['price'], axis=1)
            y = df['price']
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Scale features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            
            # Train model
            print('üîß Training Ridge model...')
            model = Ridge(alpha=1.0)
            model.fit(X_train_scaled, y_train)
            
            # Save model
            Path('Models').mkdir(exist_ok=True)
            joblib.dump(model, 'Models/housing_ridge_pipeline.pkl')
            joblib.dump(scaler, 'Models/housing_scaler_pipeline.pkl')
            
            print('‚úÖ Housing model trained and saved')
        else:
            print('‚ö†Ô∏è Data file not found, skipping training')
        "
        
    - name: Commit updated models
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        git add Dataset_1_UK_Housing/Code/Models/*.pkl || true
        git diff --staged --quiet || git commit -m "ü§ñ Auto-retrain: Housing model updated [skip ci]"
        git push || true

  retrain-electricity-model:
    runs-on: ubuntu-latest
    name: Retrain Electricity Forecast Model
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy scikit-learn xgboost joblib
        
    - name: Train Electricity Model
      run: |
        cd Dataset_2_UK_Historic_Electricity_Demand_Data/Code
        python -c "
        import pandas as pd
        import numpy as np
        from xgboost import XGBRegressor
        import joblib
        from pathlib import Path
        
        print('‚ö° Loading electricity data...')
        data_path = Path('../Data/neso_historic_demand_combined.csv')
        if data_path.exists():
            df = pd.read_csv(data_path)
            df['settlement_date'] = pd.to_datetime(df['settlement_date'])
            df = df.sort_values('settlement_date')
            
            # Basic feature engineering
            df['hour'] = df['settlement_period'] // 2
            df['day_of_week'] = df['settlement_date'].dt.dayofweek
            df['month'] = df['settlement_date'].dt.month
            df['year'] = df['settlement_date'].dt.year
            
            # Prepare features
            feature_cols = ['hour', 'day_of_week', 'month', 'year']
            X = df[feature_cols].fillna(0)
            y = df['england_wales_demand'].fillna(df['england_wales_demand'].mean())
            
            # Use last 80% for training (time series)
            split_idx = int(len(df) * 0.8)
            X_train, y_train = X[:split_idx], y[:split_idx]
            
            # Train model
            print('üîß Training XGBoost model...')
            model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)
            model.fit(X_train, y_train)
            
            # Save model
            joblib.dump(model, 'electricity_xgboost_pipeline.pkl')
            
            print('‚úÖ Electricity model trained and saved')
        else:
            print('‚ö†Ô∏è Data file not found, skipping training')
        "
        
    - name: Commit updated models
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        git add Dataset_2_UK_Historic_Electricity_Demand_Data/Code/*.pkl || true
        git diff --staged --quiet || git commit -m "ü§ñ Auto-retrain: Electricity model updated [skip ci]"
        git push || true

  deploy-notification:
    needs: [retrain-housing-model, retrain-electricity-model]
    runs-on: ubuntu-latest
    
    steps:
    - name: Deployment notification
      run: |
        echo "‚úÖ Pipeline complete! Models retrained and ready for deployment."
        echo "üöÄ Deploy Streamlit apps with updated models."
