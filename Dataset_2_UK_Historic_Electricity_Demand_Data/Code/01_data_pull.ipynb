{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c299902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: requests in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from requests) (2025.10.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul\\desktop\\ml\\aws\\machine-learning-project-tm-2025\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60300f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching dataset metadata from NESO API...\n",
      "Found 25 CSV files to download\n",
      "\n",
      "[1/25] Downloading Historic Demand Data 2009...\n",
      "Found 25 CSV files to download\n",
      "\n",
      "[1/25] Downloading Historic Demand Data 2009...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2009.csv (1.16 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2009.csv (1.16 MB)\n",
      "[2/25] Downloading Historic Demand Data 2010...\n",
      "[2/25] Downloading Historic Demand Data 2010...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2010.csv (1.18 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2010.csv (1.18 MB)\n",
      "[3/25] Downloading Historic Demand Data 2011...\n",
      "[3/25] Downloading Historic Demand Data 2011...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2011.csv (1.21 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2011.csv (1.21 MB)\n",
      "[4/25] Downloading Historic Demand Data 2012...\n",
      "[4/25] Downloading Historic Demand Data 2012...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2012.csv (1.26 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2012.csv (1.26 MB)\n",
      "[5/25] Downloading Historic Demand Data 2013...\n",
      "[5/25] Downloading Historic Demand Data 2013...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2013.csv (1.31 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2013.csv (1.31 MB)\n",
      "[6/25] Downloading Historic Demand Data 2014...\n",
      "[6/25] Downloading Historic Demand Data 2014...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2014.csv (1.32 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2014.csv (1.32 MB)\n",
      "[7/25] Downloading Historic Demand Data 2015...\n",
      "[7/25] Downloading Historic Demand Data 2015...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2015.csv (1.32 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2015.csv (1.32 MB)\n",
      "[8/25] Downloading Historic Demand Data 2016...\n",
      "[8/25] Downloading Historic Demand Data 2016...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2016.csv (1.30 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2016.csv (1.30 MB)\n",
      "[9/25] Downloading Historic Demand Data 2017...\n",
      "[9/25] Downloading Historic Demand Data 2017...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2017.csv (1.32 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2017.csv (1.32 MB)\n",
      "[10/25] Downloading Historic Demand Data 2018...\n",
      "[10/25] Downloading Historic Demand Data 2018...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2018.csv (1.32 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2018.csv (1.32 MB)\n",
      "[11/25] Downloading Historic Demand Data 2019...\n",
      "[11/25] Downloading Historic Demand Data 2019...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2019.csv (1.48 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2019.csv (1.48 MB)\n",
      "[12/25] Downloading Historic Demand Data 2020...\n",
      "[12/25] Downloading Historic Demand Data 2020...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2020.csv (1.49 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2020.csv (1.49 MB)\n",
      "[13/25] Downloading Historic Demand Data 2021...\n",
      "[13/25] Downloading Historic Demand Data 2021...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2021.csv (1.52 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2021.csv (1.52 MB)\n",
      "[14/25] Downloading Historic Demand Data 2022...\n",
      "[14/25] Downloading Historic Demand Data 2022...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2022.csv (1.60 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2022.csv (1.60 MB)\n",
      "[15/25] Downloading Historic Demand Data 2023...\n",
      "[15/25] Downloading Historic Demand Data 2023...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2023.csv (1.65 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2023.csv (1.65 MB)\n",
      "[16/25] Downloading Historic Demand Data 2024...\n",
      "[16/25] Downloading Historic Demand Data 2024...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2024.csv (1.73 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2024.csv (1.73 MB)\n",
      "[17/25] Downloading Historic Demand Data 2025...\n",
      "[17/25] Downloading Historic Demand Data 2025...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2025.csv (1.49 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2025.csv (1.49 MB)\n",
      "[18/25] Downloading Historic Demand Data 2001...\n",
      "[18/25] Downloading Historic Demand Data 2001...\n",
      "  ✓ Saved to ..\\Data\\demanddata_2001.csv (1.39 MB)\n",
      "  ✓ Saved to ..\\Data\\demanddata_2001.csv (1.39 MB)\n",
      "[19/25] Downloading Historic Demand Data 2002...\n",
      "[19/25] Downloading Historic Demand Data 2002...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Create directory for downloads\n",
    "download_dir = Path(\"../Data\")\n",
    "download_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Fetching dataset metadata from NESO API...\")\n",
    "\n",
    "# Get all resources from the API\n",
    "api_url = \"https://api.neso.energy/api/3/action/package_show?id=historic-demand-data\"\n",
    "response = requests.get(api_url)\n",
    "data = response.json()\n",
    "\n",
    "# Extract all CSV resources and construct proper download URLs\n",
    "csv_resources = []\n",
    "if data['success']:\n",
    "    dataset_id = data['result']['id']\n",
    "    resources = data['result']['resources']\n",
    "    \n",
    "    for resource in resources:\n",
    "        if resource['format'].upper() == 'CSV':\n",
    "            # Construct the download URL using the NESO API pattern\n",
    "            download_url = f\"https://api.neso.energy/dataset/{dataset_id}/resource/{resource['id']}/download/{resource['url'].split('/')[-1] if resource.get('url') else resource['name'].replace(' ', '_') + '.csv'}\"\n",
    "            \n",
    "            # Alternative: try using the resource's URL directly if it exists\n",
    "            if resource.get('url') and resource['url'].startswith('http'):\n",
    "                download_url = resource['url']\n",
    "            \n",
    "            csv_resources.append({\n",
    "                'name': resource['name'],\n",
    "                'url': download_url,\n",
    "                'resource_id': resource['id'],\n",
    "                'filename': resource['url'].split('/')[-1] if resource.get('url') else f\"{resource['name'].replace(' ', '_')}.csv\"\n",
    "            })\n",
    "\n",
    "print(f\"Found {len(csv_resources)} CSV files to download\\n\")\n",
    "\n",
    "# Download all CSV files\n",
    "downloaded_files = []\n",
    "for i, resource in enumerate(csv_resources, 1):\n",
    "    print(f\"[{i}/{len(csv_resources)}] Downloading {resource['name']}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(resource['url'], timeout=60, allow_redirects=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        filepath = download_dir / resource['filename']\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        downloaded_files.append(filepath)\n",
    "        print(f\"  ✓ Saved to {filepath} ({len(response.content) / 1024 / 1024:.2f} MB)\")\n",
    "        \n",
    "        # Small delay to be respectful to the server\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error downloading {resource['name']}: {e}\")\n",
    "        print(f\"     URL attempted: {resource['url']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Downloaded {len(downloaded_files)} files successfully\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Combine all CSV files\n",
    "print(\"Combining all CSV files into one dataset...\")\n",
    "\n",
    "all_dataframes = []\n",
    "for filepath in downloaded_files:\n",
    "    try:\n",
    "        print(f\"Reading {filepath.name}...\")\n",
    "        # FIX: Parse SETTLEMENT_DATE properly during read\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Convert SETTLEMENT_DATE to datetime immediately after reading\n",
    "        if 'SETTLEMENT_DATE' in df.columns:\n",
    "            # Parse the date format like \"01-JAN-2024\"\n",
    "            df['SETTLEMENT_DATE'] = pd.to_datetime(df['SETTLEMENT_DATE'], format='%d-%b-%Y', errors='coerce')\n",
    "        \n",
    "        all_dataframes.append(df)\n",
    "        print(f\"  ✓ Loaded {len(df):,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error reading {filepath.name}: {e}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Sort by date if SETTLEMENT_DATE column exists\n",
    "    if 'SETTLEMENT_DATE' in combined_df.columns:\n",
    "        combined_df = combined_df.sort_values(['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD'], ignore_index=True)\n",
    "    \n",
    "    # Save combined dataset\n",
    "    output_file = \"../Data/neso_historic_demand_combined.csv\"\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ Combined dataset saved to: {output_file}\")\n",
    "    print(f\"  Total rows: {len(combined_df):,}\")\n",
    "    print(f\"  Total columns: {len(combined_df.columns)}\")\n",
    "    print(f\"  File size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nPreview of combined data:\")\n",
    "    print(combined_df.head())\n",
    "    \n",
    "    # Display column names\n",
    "    print(f\"\\nColumns: {', '.join(combined_df.columns)}\")\n",
    "    \n",
    "    # Display basic statistics\n",
    "    if 'SETTLEMENT_DATE' in combined_df.columns:\n",
    "        print(f\"\\nDate range: {combined_df['SETTLEMENT_DATE'].min()} to {combined_df['SETTLEMENT_DATE'].max()}\")\n",
    "        print(f\"Valid dates: {combined_df['SETTLEMENT_DATE'].notna().sum():,} / {len(combined_df):,}\")\n",
    "else:\n",
    "    print(\"No data to combine!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_12640\\820260418.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../Data/neso_historic_demand_combined.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original column names:\n",
      "['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD', 'ND', 'TSD', 'ENGLAND_WALES_DEMAND', 'EMBEDDED_WIND_GENERATION', 'EMBEDDED_WIND_CAPACITY', 'EMBEDDED_SOLAR_GENERATION', 'EMBEDDED_SOLAR_CAPACITY', 'NON_BM_STOR', 'PUMP_STORAGE_PUMPING', 'IFA_FLOW', 'IFA2_FLOW', 'BRITNED_FLOW', 'MOYLE_FLOW', 'EAST_WEST_FLOW', 'NEMO_FLOW', 'NSL_FLOW', 'ELECLINK_FLOW', 'VIKING_FLOW', 'GREENLINK_FLOW', 'SCOTTISH_TRANSFER']\n",
      "\n",
      "Renamed column names:\n",
      "['settlement_date', 'settlement_period', 'nd', 'tsd', 'england_wales_demand', 'embedded_wind_generation', 'embedded_wind_capacity', 'embedded_solar_generation', 'embedded_solar_capacity', 'non_bm_stor', 'pump_storage_pumping', 'ifa_flow', 'ifa2_flow', 'britned_flow', 'moyle_flow', 'east_west_flow', 'nemo_flow', 'nsl_flow', 'eleclink_flow', 'viking_flow', 'greenlink_flow', 'scottish_transfer']\n",
      "\n",
      "✓ Columns renamed and file saved successfully!\n",
      "  Total rows: 435,408\n",
      "  Total columns: 22\n",
      "✓ Columns renamed and file saved successfully!\n",
      "  Total rows: 435,408\n",
      "  Total columns: 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined CSV file\n",
    "df = pd.read_csv(\"../Data/neso_historic_demand_combined.csv\")\n",
    "\n",
    "print(\"Original column names:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Rename columns: remove spaces and make lowercase\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "print(\"Renamed column names:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Save the file with renamed columns\n",
    "df.to_csv(\"../Data/neso_historic_demand_combined.csv\", index=False)\n",
    "\n",
    "print(\"✓ Columns renamed and file saved successfully!\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
