{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6871773b",
   "metadata": {},
   "source": [
    "# UK Historic Electricity Demand - Final Model Comparison\n",
    "**Author:** Abdul Salam Aldabik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6c6700",
   "metadata": {},
   "source": [
    "## 1. Load Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f285f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics from complete model training\n",
    "print(\"üìÇ Loading model metrics...\\n\")\n",
    "\n",
    "# Main models from 05_complete_model_training.ipynb\n",
    "main_models_path = '../Data/complete_model_comparison.csv'\n",
    "if os.path.exists(main_models_path):\n",
    "    df_all = pd.read_csv(main_models_path)\n",
    "    print(f\"‚úÖ Loaded models: {len(df_all)} models\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \"*25 + \"ALL MODELS LOADED\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_all[['Model', 'MAE', 'RMSE', 'MAPE', 'R¬≤']].to_string(index=False))\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  File not found: {main_models_path}\")\n",
    "    print(\"‚ö†Ô∏è  Run 05_complete_model_training.ipynb first!\")\n",
    "    df_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ca7a6",
   "metadata": {},
   "source": [
    "## 2. Identify Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Sort by MAPE (best metric for forecasting)\n",
    "    df_all = df_all.sort_values('MAPE').reset_index(drop=True)\n",
    "    best_model = df_all.iloc[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÜ BEST PERFORMING MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nModel: {best_model['Model']}\")\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"  MAPE: {best_model['MAPE']:.2f}% (lower is better)\")\n",
    "    print(f\"  MAE:  {best_model['MAE']:,.0f} MW\")\n",
    "    print(f\"  RMSE: {best_model['RMSE']:,.0f} MW\")\n",
    "    print(f\"  R¬≤:   {best_model['R¬≤']:.4f} (closer to 1 is better)\")\n",
    "    \n",
    "    if 'Training Time (s)' in best_model.index:\n",
    "        print(f\"  Training Time: {best_model['Training Time (s)']:.1f} seconds\")\n",
    "    \n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    print(f\"   On average, predictions are {best_model['MAPE']:.2f}% off from actual demand\")\n",
    "    print(f\"   For 30,000 MW demand ‚Üí error of ~{30000 * best_model['MAPE']/100:,.0f} MW\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4728134",
   "metadata": {},
   "source": [
    "## 3. Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0483d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty and len(df_all) > 1:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # MAPE Comparison (Most Important)\n",
    "    axes[0, 0].barh(df_all['Model'], df_all['MAPE'], color='#3498db')\n",
    "    axes[0, 0].set_xlabel('MAPE (%)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_title('Mean Absolute Percentage Error (Lower is Better)', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "    for i, (idx, row) in enumerate(df_all.iterrows()):\n",
    "        axes[0, 0].text(row['MAPE'] + 0.3, i, f\"{row['MAPE']:.2f}%\", \n",
    "                       va='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # MAE Comparison\n",
    "    axes[0, 1].barh(df_all['Model'], df_all['MAE'], color='#2ecc71')\n",
    "    axes[0, 1].set_xlabel('MAE (MW)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_title('Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "    for i, (idx, row) in enumerate(df_all.iterrows()):\n",
    "        axes[0, 1].text(row['MAE'] + 100, i, f\"{row['MAE']:,.0f}\", \n",
    "                       va='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # RMSE Comparison\n",
    "    axes[1, 0].barh(df_all['Model'], df_all['RMSE'], color='#e74c3c')\n",
    "    axes[1, 0].set_xlabel('RMSE (MW)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_title('Root Mean Squared Error', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "    for i, (idx, row) in enumerate(df_all.iterrows()):\n",
    "        axes[1, 0].text(row['RMSE'] + 100, i, f\"{row['RMSE']:,.0f}\", \n",
    "                       va='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # R¬≤ Comparison\n",
    "    axes[1, 1].barh(df_all['Model'], df_all['R¬≤'], color='#9b59b6')\n",
    "    axes[1, 1].set_xlabel('R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_title('R¬≤ Score (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "    for i, (idx, row) in enumerate(df_all.iterrows()):\n",
    "        axes[1, 1].text(row['R¬≤'] + 0.01, i, f\"{row['R¬≤']:.4f}\", \n",
    "                       va='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../Output/final_model_comparison_all_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Comparison visualization saved: final_model_comparison_all_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc801f16",
   "metadata": {},
   "source": [
    "## 4. Model Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL RANKINGS BY DIFFERENT METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nü•á BEST BY MAPE (Primary Metric for Forecasting):\")\n",
    "    top_mape = df_all.nsmallest(3, 'MAPE')\n",
    "    for i, (idx, row) in enumerate(top_mape.iterrows(), 1):\n",
    "        medal = [\"ü•á\", \"ü•à\", \"ü•â\"][i-1] if i <= 3 else f\"{i}.\"\n",
    "        print(f\"   {medal} {row['Model']}: {row['MAPE']:.2f}%\")\n",
    "    \n",
    "    print(\"\\nü•á BEST BY MAE (Absolute Error in MW):\")\n",
    "    top_mae = df_all.nsmallest(3, 'MAE')\n",
    "    for i, (idx, row) in enumerate(top_mae.iterrows(), 1):\n",
    "        medal = [\"ü•á\", \"ü•à\", \"ü•â\"][i-1] if i <= 3 else f\"{i}.\"\n",
    "        print(f\"   {medal} {row['Model']}: {row['MAE']:,.0f} MW\")\n",
    "    \n",
    "    print(\"\\nü•á BEST BY R¬≤ (Variance Explained):\")\n",
    "    top_r2 = df_all.nlargest(3, 'R¬≤')\n",
    "    for i, (idx, row) in enumerate(top_r2.iterrows(), 1):\n",
    "        medal = [\"ü•á\", \"ü•à\", \"ü•â\"][i-1] if i <= 3 else f\"{i}.\"\n",
    "        print(f\"   {medal} {row['Model']}: {row['R¬≤']:.4f}\")\n",
    "    \n",
    "    if 'Training Time (s)' in df_all.columns:\n",
    "        print(\"\\n‚ö° FASTEST TRAINING TIME:\")\n",
    "        df_with_time = df_all[df_all['Training Time (s)'] > 0].copy()\n",
    "        if len(df_with_time) > 0:\n",
    "            top_fast = df_with_time.nsmallest(3, 'Training Time (s)')\n",
    "            for i, (idx, row) in enumerate(top_fast.iterrows(), 1):\n",
    "                print(f\"   {i}. {row['Model']}: {row['Training Time (s)']:.1f}s (MAPE: {row['MAPE']:.2f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b498dca9",
   "metadata": {},
   "source": [
    "## 5. Detailed Analysis & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*20 + \"DETAILED ANALYSIS & CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not df_all.empty and len(df_all) > 1:\n",
    "    best = df_all.iloc[0]\n",
    "    worst = df_all.iloc[-1]\n",
    "    \n",
    "    print(f\"\\nüìä OVERALL STATISTICS:\")\n",
    "    print(f\"   Total models compared: {len(df_all)}\")\n",
    "    print(f\"   MAPE range: {df_all['MAPE'].min():.2f}% to {df_all['MAPE'].max():.2f}%\")\n",
    "    print(f\"   Improvement: {worst['MAPE'] - best['MAPE']:.2f} percentage points from worst to best\")\n",
    "    print(f\"   MAE range: {df_all['MAE'].min():,.0f} MW to {df_all['MAE'].max():,.0f} MW\")\n",
    "    print(f\"   R¬≤ range: {df_all['R¬≤'].min():.4f} to {df_all['R¬≤'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ WINNER: {best['Model']}\")\n",
    "    print(f\"   Why: Lowest MAPE of {best['MAPE']:.2f}%\")\n",
    "    print(f\"   Practical Impact:\")\n",
    "    print(f\"     ‚Ä¢ Average daily demand: ~30,000 MW\")\n",
    "    print(f\"     ‚Ä¢ Model error: ~{30000 * best['MAPE']/100:,.0f} MW\")\n",
    "    print(f\"     ‚Ä¢ Accuracy: {100 - best['MAPE']:.2f}% on average\")\n",
    "    \n",
    "    print(f\"\\nüìâ LEAST ACCURATE: {worst['Model']}\")\n",
    "    print(f\"   MAPE: {worst['MAPE']:.2f}% (vs best: {best['MAPE']:.2f}%)\")\n",
    "    print(f\"   Performance gap: {((worst['MAPE'] - best['MAPE']) / best['MAPE'] * 100):.1f}% worse than best model\")\n",
    "    \n",
    "    # Model insights\n",
    "    print(f\"\\nüî¨ KEY INSIGHTS:\")\n",
    "    \n",
    "    if any('XGBoost' in str(m) for m in df_all['Model']):\n",
    "        xgb_row = df_all[df_all['Model'].str.contains('XGBoost', case=False, na=False)].iloc[0]\n",
    "        print(f\"   ‚úÖ XGBoost: Fast training ({xgb_row.get('Training Time (s)', 0):.1f}s), excellent accuracy ({xgb_row['MAPE']:.2f}%)\")\n",
    "        print(f\"      Best for: Production deployment, feature importance analysis\")\n",
    "    \n",
    "    if any('LSTM' in str(m) for m in df_all['Model']):\n",
    "        lstm_row = df_all[df_all['Model'].str.contains('LSTM', case=False, na=False)].iloc[0]\n",
    "        print(f\"   ‚úÖ LSTM: Deep learning approach ({lstm_row['MAPE']:.2f}% MAPE)\")\n",
    "        print(f\"      Best for: Capturing complex temporal patterns\")\n",
    "    \n",
    "    if any('Prophet' in str(m) for m in df_all['Model']):\n",
    "        prophet_row = df_all[df_all['Model'].str.contains('Prophet', case=False, na=False)].iloc[0]\n",
    "        print(f\"   ‚úÖ Prophet: Statistical model ({prophet_row['MAPE']:.2f}% MAPE)\")\n",
    "        print(f\"      Best for: Interpretability, seasonality analysis\")\n",
    "    \n",
    "    if any('Ensemble' in str(m) for m in df_all['Model']):\n",
    "        ens_row = df_all[df_all['Model'].str.contains('Ensemble', case=False, na=False)].iloc[0]\n",
    "        print(f\"   ‚úÖ Ensemble: Combines all models ({ens_row['MAPE']:.2f}% MAPE)\")\n",
    "        print(f\"      Best for: Robustness, critical applications\")\n",
    "    \n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    print(f\"   1. DEPLOY: {best['Model']} for production (best accuracy)\")\n",
    "    print(f\"   2. MONITOR: Track performance monthly, retrain with new data\")\n",
    "    print(f\"   3. BACKUP: Use Ensemble for high-stakes forecasts (more robust)\")\n",
    "    print(f\"   4. ANALYZE: Use XGBoost feature importance for insights\")\n",
    "    print(f\"   5. VALIDATE: Continuous A/B testing against actual demand\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47245a",
   "metadata": {},
   "source": [
    "## 6. Save Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35800b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Save comparison table\n",
    "    df_all.to_csv('../Data/all_models_final_comparison.csv', index=False)\n",
    "    print(\"‚úÖ Saved: all_models_final_comparison.csv\")\n",
    "    \n",
    "    # Create text report\n",
    "    report_path = '../Output/final_model_comparison_report.txt'\n",
    "    \n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\" \"*20 + \"FINAL MODEL COMPARISON REPORT\\n\")\n",
    "        f.write(\" \"*15 + \"UK Electricity Demand Forecasting\\n\")\n",
    "        f.write(\" \"*25 + f\"Dataset 2 - Team Project\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Total Models Compared: {len(df_all)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"ALL MODELS (Sorted by MAPE - Best to Worst):\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        f.write(df_all[['Model', 'MAE', 'RMSE', 'MAPE', 'R¬≤']].to_string(index=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        best = df_all.iloc[0]\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"BEST PERFORMING MODEL\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"Model: {best['Model']}\\n\\n\")\n",
    "        f.write(f\"Performance Metrics:\\n\")\n",
    "        f.write(f\"  MAPE: {best['MAPE']:.2f}%\\n\")\n",
    "        f.write(f\"  MAE:  {best['MAE']:,.0f} MW\\n\")\n",
    "        f.write(f\"  RMSE: {best['RMSE']:,.0f} MW\\n\")\n",
    "        f.write(f\"  R¬≤:   {best['R¬≤']:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Interpretation:\\n\")\n",
    "        f.write(f\"  - Predictions are {best['MAPE']:.2f}% off from actual demand on average\\n\")\n",
    "        f.write(f\"  - For 30,000 MW demand, error is approximately {30000 * best['MAPE']/100:,.0f} MW\\n\")\n",
    "        f.write(f\"  - Model explains {best['R¬≤']*100:.2f}% of variance in demand\\n\\n\")\n",
    "        \n",
    "        f.write(\"RECOMMENDATIONS:\\n\")\n",
    "        f.write(f\"  1. Deploy {best['Model']} for production forecasting\\n\")\n",
    "        f.write(\"  2. Use Ensemble model for critical applications (more robust)\\n\")\n",
    "        f.write(\"  3. Retrain models monthly with new data\\n\")\n",
    "        f.write(\"  4. Monitor performance continuously\\n\")\n",
    "        f.write(\"  5. Validate predictions against actual demand\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"END OF REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Final report saved: {report_path}\")\n",
    "    print(\"\\n‚úÖ ALL ANALYSIS COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207eafc5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Analysis Complete:**\n",
    "- ‚úÖ Loaded metrics from all trained models\n",
    "- ‚úÖ Identified best model by MAPE, MAE, RMSE, R¬≤\n",
    "- ‚úÖ Created comprehensive visualizations\n",
    "- ‚úÖ Analyzed performance trade-offs\n",
    "- ‚úÖ Generated detailed recommendations\n",
    "- ‚úÖ Saved comparison table and report\n",
    "\n",
    "**Key Findings:**\n",
    "- **Best Model:** XGBoost (3.00% MAPE)\n",
    "- **Most Robust:** Ensemble (4.71% MAPE)\n",
    "- **Fastest Training:** XGBoost (5.6 seconds)\n",
    "- **Deepest Patterns:** LSTM (7.23% MAPE)\n",
    "\n",
    "**Ready For:**\n",
    "- ‚úÖ Presentation (28 November 2025)\n",
    "- ‚úÖ Deployment via Streamlit\n",
    "- ‚úÖ Production forecasting\n",
    "- ‚úÖ Project submission"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
