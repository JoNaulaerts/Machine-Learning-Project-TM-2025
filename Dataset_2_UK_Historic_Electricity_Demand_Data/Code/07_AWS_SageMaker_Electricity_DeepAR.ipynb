{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dd8c369",
   "metadata": {},
   "source": [
    "# UK Electricity Demand Forecasting - AWS SageMaker DeepAR\n",
    "**Author:** Abdul Salam Aldabik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72806bd2",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0780b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (only if not already installed in SageMaker)\n",
    "# !pip install sagemaker boto3 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb35cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"SageMaker version: {sagemaker.__version__}\")\n",
    "print(f\"Boto3 version: {boto3.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d4c87",
   "metadata": {},
   "source": [
    "## 2. SageMaker Session and Role Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10829d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker session and get execution role\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'electricity-demand-forecasting'\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"S3 Bucket: {bucket}\")\n",
    "print(f\"S3 Prefix: {prefix}\")\n",
    "print(f\"Region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627fd54",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "\n",
    "**STEP 1:** Upload `neso_historic_demand_combined.csv` to SageMaker:\n",
    "- Drag and drop the file into the JupyterLab file browser (left sidebar)\n",
    "- Or click the Upload button (↑ icon) and select the file\n",
    "\n",
    "**STEP 2:** Run the cell below to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d04723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the electricity data\n",
    "df = pd.read_csv('neso_historic_demand_combined.csv')\n",
    "df['SETTLEMENT_DATE'] = pd.to_datetime(df['SETTLEMENT_DATE'])\n",
    "df = df.sort_values(['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD'])\n",
    "\n",
    "print(f\"✅ Dataset loaded: {df.shape}\")\n",
    "print(f\"Date range: {df['SETTLEMENT_DATE'].min()} to {df['SETTLEMENT_DATE'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e1672",
   "metadata": {},
   "source": [
    "## 4. Prepare Time Series for DeepAR\n",
    "\n",
    "DeepAR requires data in JSON Lines format with:\n",
    "- `start`: timestamp of first observation\n",
    "- `target`: array of time series values\n",
    "- `cat` (optional): categorical features\n",
    "- `dynamic_feat` (optional): time-varying features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ND (National Demand) as target\n",
    "target_column = 'ND'\n",
    "\n",
    "# Create datetime index combining date and period\n",
    "df['datetime'] = df.apply(\n",
    "    lambda row: row['SETTLEMENT_DATE'] + timedelta(minutes=30 * (row['SETTLEMENT_PERIOD'] - 1)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Set datetime as index and get target series\n",
    "df = df.set_index('datetime').sort_index()\n",
    "ts_data = df[target_column].values\n",
    "\n",
    "print(f\"Time series length: {len(ts_data)}\")\n",
    "print(f\"Time series range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Target column: {target_column}\")\n",
    "print(f\"Missing values: {np.isnan(ts_data).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65343683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "if np.isnan(ts_data).sum() > 0:\n",
    "    ts_data = pd.Series(ts_data).fillna(method='ffill').fillna(method='bfill').values\n",
    "    print(f\"Filled {np.isnan(ts_data).sum()} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "# Use last 7 days (336 half-hour periods) for testing\n",
    "prediction_length = 336  # 7 days * 48 half-hours\n",
    "train_data = ts_data[:-prediction_length]\n",
    "test_data = ts_data\n",
    "\n",
    "print(f\"Training series length: {len(train_data)}\")\n",
    "print(f\"Full series length: {len(test_data)}\")\n",
    "print(f\"Prediction length: {prediction_length} (7 days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88770930",
   "metadata": {},
   "source": [
    "## 5. Create DeepAR Format (JSON Lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ff5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_json_obj(ts, start_date, cat=None):\n",
    "    \"\"\"Convert time series to DeepAR JSON format\"\"\"\n",
    "    obj = {\n",
    "        \"start\": start_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"target\": ts.tolist()\n",
    "    }\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "# Get start date\n",
    "start_date = df.index[0]\n",
    "\n",
    "# Create training and test JSON objects\n",
    "train_json = series_to_json_obj(train_data, start_date)\n",
    "test_json = series_to_json_obj(test_data, start_date)\n",
    "\n",
    "print(\"Sample training JSON:\")\n",
    "print(json.dumps({**train_json, 'target': train_json['target'][:10] + ['...']} , indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed822f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON Lines files\n",
    "def write_json_lines(data, filename):\n",
    "    \"\"\"Write JSON objects to file in JSON Lines format\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        # DeepAR expects one JSON object per line\n",
    "        json.dump(data, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "train_file = 'train.json'\n",
    "test_file = 'test.json'\n",
    "\n",
    "write_json_lines(train_json, train_file)\n",
    "write_json_lines(test_json, test_file)\n",
    "\n",
    "print(f\"Created {train_file}\")\n",
    "print(f\"Created {test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce215a",
   "metadata": {},
   "source": [
    "## 6. Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "train_s3_path = sess.upload_data(\n",
    "    path=train_file,\n",
    "    bucket=bucket,\n",
    "    key_prefix=f'{prefix}/train'\n",
    ")\n",
    "\n",
    "test_s3_path = sess.upload_data(\n",
    "    path=test_file,\n",
    "    bucket=bucket,\n",
    "    key_prefix=f'{prefix}/test'\n",
    ")\n",
    "\n",
    "print(f\"Training data: {train_s3_path}\")\n",
    "print(f\"Test data: {test_s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281da9d",
   "metadata": {},
   "source": [
    "## 7. Configure SageMaker DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DeepAR container image\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "image_uri = retrieve('forecasting-deepar', sess.boto_region_name, version='latest')\n",
    "print(f\"DeepAR container: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepAR estimator\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "# freq: 30min (half-hourly data)\n",
    "estimator.set_hyperparameters(\n",
    "    time_freq='30min',\n",
    "    context_length=336,  # 7 days context\n",
    "    prediction_length=prediction_length,  # 7 days forecast\n",
    "    num_cells=40,\n",
    "    num_layers=2,\n",
    "    likelihood='gaussian',\n",
    "    epochs=100,\n",
    "    mini_batch_size=32,\n",
    "    learning_rate=0.001,\n",
    "    dropout_rate=0.1,\n",
    "    early_stopping_patience=10\n",
    ")\n",
    "\n",
    "print(\"DeepAR estimator configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48851e79",
   "metadata": {},
   "source": [
    "## 8. Train the Model\n",
    "\n",
    "**⚠️ This will take 10-20 minutes and incur AWS charges!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training input channels\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=train_s3_path,\n",
    "    content_type='application/json'\n",
    ")\n",
    "\n",
    "test_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=test_s3_path,\n",
    "    content_type='application/json'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting DeepAR training job...\")\n",
    "print(\"This will take approximately 10-20 minutes.\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "estimator.fit({'train': train_input, 'test': test_input})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2478a004",
   "metadata": {},
   "source": [
    "## 9. Deploy the Model\n",
    "\n",
    "**⚠️ Deploying creates an endpoint that incurs hourly charges!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to endpoint\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "print(\"Deploying DeepAR model...\")\n",
    "print(\"This will take 5-10 minutes.\")\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Model deployed to endpoint: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397a96e",
   "metadata": {},
   "source": [
    "## 10. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare prediction request\n",
    "request_data = {\n",
    "    \"instances\": [train_json],\n",
    "    \"configuration\": {\n",
    "        \"num_samples\": 100,\n",
    "        \"output_types\": [\"mean\", \"quantiles\"],\n",
    "        \"quantiles\": [\"0.1\", \"0.5\", \"0.9\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "results = predictor.predict(request_data)\n",
    "print(\"✅ Predictions complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions\n",
    "predictions = results['predictions'][0]\n",
    "mean_forecast = np.array(predictions['mean'])\n",
    "quantile_10 = np.array(predictions['quantiles']['0.1'])\n",
    "quantile_50 = np.array(predictions['quantiles']['0.5'])\n",
    "quantile_90 = np.array(predictions['quantiles']['0.9'])\n",
    "\n",
    "print(f\"Forecast length: {len(mean_forecast)}\")\n",
    "print(f\"Mean forecast range: {mean_forecast.min():.2f} to {mean_forecast.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87600886",
   "metadata": {},
   "source": [
    "## 11. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea238afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual test values\n",
    "actual_test = ts_data[-prediction_length:]\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(actual_test, mean_forecast)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actual_test, mean_forecast)\n",
    "r2 = r2_score(actual_test, mean_forecast)\n",
    "mape = np.mean(np.abs((actual_test - mean_forecast) / actual_test)) * 100\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AWS SageMaker DeepAR - Model Performance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mean Squared Error (MSE):     {mse:,.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:,.2f} MW\")\n",
    "print(f\"Mean Absolute Error (MAE):     {mae:,.2f} MW\")\n",
    "print(f\"Mean Absolute % Error (MAPE):  {mape:.2f}%\")\n",
    "print(f\"R² Score:                      {r2:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7c05b",
   "metadata": {},
   "source": [
    "## 12. Visualize Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date range for forecast\n",
    "forecast_dates = pd.date_range(\n",
    "    start=df.index[-prediction_length],\n",
    "    periods=prediction_length,\n",
    "    freq='30min'\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot historical data (last 30 days)\n",
    "historical_window = 1440  # 30 days\n",
    "plt.plot(\n",
    "    df.index[-historical_window-prediction_length:-prediction_length],\n",
    "    ts_data[-historical_window-prediction_length:-prediction_length],\n",
    "    label='Historical',\n",
    "    color='blue',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Plot actual test data\n",
    "plt.plot(\n",
    "    forecast_dates,\n",
    "    actual_test,\n",
    "    label='Actual',\n",
    "    color='green',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Plot forecast\n",
    "plt.plot(\n",
    "    forecast_dates,\n",
    "    mean_forecast,\n",
    "    label='DeepAR Forecast (Mean)',\n",
    "    color='red',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Plot confidence intervals\n",
    "plt.fill_between(\n",
    "    forecast_dates,\n",
    "    quantile_10,\n",
    "    quantile_90,\n",
    "    alpha=0.3,\n",
    "    color='red',\n",
    "    label='80% Confidence Interval'\n",
    ")\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Electricity Demand (MW)')\n",
    "plt.title('DeepAR Electricity Demand Forecast (7-day)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6a5a3",
   "metadata": {},
   "source": [
    "## 13. Save Results for Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to file\n",
    "results = {\n",
    "    'model': 'AWS SageMaker DeepAR',\n",
    "    'mse': float(mse),\n",
    "    'rmse': float(rmse),\n",
    "    'mae': float(mae),\n",
    "    'mape': float(mape),\n",
    "    'r2': float(r2),\n",
    "    'forecast_horizon': prediction_length,\n",
    "    'forecast_horizon_days': 7,\n",
    "    'training_samples': len(train_data),\n",
    "    'test_samples': len(actual_test),\n",
    "    'endpoint_name': predictor.endpoint_name\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('aws_deepar_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to aws_deepar_results.json\")\n",
    "print(\"\\nResults:\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25546243",
   "metadata": {},
   "source": [
    "## 14. ⚠️ IMPORTANT: Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70070b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint to stop charges\n",
    "print(f\"Deleting endpoint: {predictor.endpoint_name}\")\n",
    "predictor.delete_endpoint()\n",
    "print(\"✅ Endpoint deleted successfully!\")\n",
    "print(\"\\n⚠️ Remember to also stop your notebook instance in the SageMaker console!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3e22e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. ✅ Loaded UK electricity demand time series data\n",
    "2. ✅ Prepared data in DeepAR JSON format\n",
    "3. ✅ Uploaded to S3\n",
    "4. ✅ Trained AWS SageMaker DeepAR model\n",
    "5. ✅ Generated probabilistic forecasts with confidence intervals\n",
    "6. ✅ Evaluated model performance\n",
    "7. ✅ Saved results for comparison\n",
    "8. ✅ Cleaned up resources\n",
    "\n",
    "**Next Steps:**\n",
    "- Download this notebook from SageMaker\n",
    "- Save to GitHub as `07_AWS_SageMaker_Model.ipynb`\n",
    "- Add results to model comparison notebook\n",
    "- Stop your SageMaker notebook instance!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
